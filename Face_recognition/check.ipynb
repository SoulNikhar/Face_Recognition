{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605e9fe0-389e-4e63-99bf-c56015ab9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(\"OpenCV version:\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffdd8e-58a4-4806-9408-bf44227af2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7130585-da52-4df7-a586-f6f93cdcb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "pixels = cv2.imread('team.jpg')\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(pixels, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "bboxes = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=9, minSize=(30, 30))\n",
    "\n",
    "\n",
    "for (x, y, width, height) in bboxes:\n",
    "    cv2.rectangle(pixels, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow('Detected Objects', pixels)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96264f4f-9928-4e63-80a6-e6ae797405a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('team.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.05,\n",
    "    minNeighbors=3,\n",
    "    minSize=(30, 30),\n",
    "    maxSize=(300, 300)\n",
    ")\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ba81aa8-3400-4039-a9fa-ae922312fdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "347e1f78-595d-42c1-a867-dd2ce1fd9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face detector (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Read the image from the file\n",
    "img = cv2.imread('team.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Optionally, apply histogram equalization for better contrast\n",
    "gray = cv2.equalizeHist(gray)\n",
    "\n",
    "\n",
    "# Detect faces in the image with modified parameters\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "# Draw rectangles around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# Display the output image with the detected faces\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "# Wait indefinitely for a key press\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abd1c50d-f771-450d-b9e8-3c6a8f4310cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('team.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "# Loop until the window is closed by the user\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:  # Optionally allow exiting with ESC key\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037c849-8248-4d57-8378-66055da8a2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7093b74-d29f-4d7d-a45a-aa5b33436ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1c9bff4-47b0-463b-a0a4-3f9acba3f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread(r\"C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img\\acheck2.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    cv2.putText(img, 'Name', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabbd00-a5d8-45c8-a5c6-1cc1c56be0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b32890d-b30e-4bee-b7fc-07edd20c1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# List of names corresponding to each detected face\n",
    "names = ['Person 1', 'Person 2', 'Person 3', 'Person 4','Person 5', 'Person 6', 'Person 7', 'Person 8','Person 1', 'Person 2', 'Person 3', 'Person 4','Person 5', 'Person 6', 'Person 7', 'Person 8']  # Add as many names as there are faces\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('img4.jpeg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "# Ensure that the number of names matches the naumber of detected faces\n",
    "for i, (x, y, w, h) in enumerate(faces):\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    cv2.putText(img, names[i], (x, y - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.2, (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f2a7f-0104-415c-8c9c-aaf2092ce926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5121fbb0-5690-4ca6-8c38-d83ee9c3ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load image\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            # Handle cases with no faces or multiple faces in the image\n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in group photo\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names):\n",
    "    # Load the group image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    recognized_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # If there are known encodings, find the best match\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "\n",
    "        # Check if a match was found\n",
    "        if best_match_index is not None and matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "    \n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    # Load the existing attendance file or create a new one\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    # Save the updated attendance sheet\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        # Set the bounding box color based on whether the face is recognized\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        \n",
    "        # Add the student's name\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    # Load student images and encode faces\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    # Process each group photo in the directory\n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            # Mark attendance\n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            # Draw bounding boxes around recognized faces\n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            # Display the processed image\n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c979b3-202f-42d9-ae75-96f74b119cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830398e-264a-48c4-826f-079d23057882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94013f41-d982-4d7b-8720-c19ea28a9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load image\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            # Handle cases with no faces or multiple faces in the image\n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in group photo\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.6):\n",
    "    # Load the group image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    recognized_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "    \n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    # Load the existing attendance file or create a new one\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    # Save the updated attendance sheet\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        # Set the bounding box color based on whether the face is recognized\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        \n",
    "        # Add the student's name\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    # Load student images and encode faces\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    # Process each group photo in the directory\n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            # Mark attendance\n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            # Draw bounding boxes around recognized faces\n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            # Display the processed image\n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a1fd4-24f2-4a03-aaef-62f56d380fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd9da9-36da-4e76-8334-4d0b4406443a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf24709a-97a3-404a-9d67-c50270387da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load image\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            # Handle cases with no faces or multiple faces in the image\n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in group photo\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5):\n",
    "    # Load the group image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    recognized_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "    \n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    # Load the existing attendance file or create a new one\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    # Save the updated attendance sheet\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        # Set the bounding box color based on whether the face is recognized\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        \n",
    "        # Add the student's name\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    # Load student images and encode faces\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    # Process each group photo in the directory\n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            # Mark attendance\n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            # Draw bounding boxes around recognized faces\n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            # Display the processed image\n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n",
    "\n",
    "# in this code some times it detected someones other face as other one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa76c33-e8fa-4841-a899-1ee357896ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13823dc9-0cf6-4f4e-bb31-ae7bf2474ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bd90b-014c-4a9c-ad17-893bfecbbfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f687df34-bcf1-4626-af29-be55e4b1184c",
   "metadata": {},
   "source": [
    "# face recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f47a9d23-abbc-4b70-ab4d-1927b73ee61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.4):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "# Recognize faces in group photo with multiple passes and verification\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5):\n",
    "    img = cv2.imread(image_path)\n",
    "    transformations = apply_transformations(img)\n",
    "    transformations.insert(0, img)  # Include the original image\n",
    "\n",
    "    recognized_faces_dict = {}\n",
    "\n",
    "    for transformed_img in transformations:\n",
    "        transformed_img_rgb = cv2.cvtColor(transformed_img, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(transformed_img_rgb)\n",
    "        face_encodings = face_recognition.face_encodings(transformed_img_rgb, face_locations)\n",
    "\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "\n",
    "            # Track occurrences\n",
    "            if face_location not in recognized_faces_dict:\n",
    "                recognized_faces_dict[face_location] = {}\n",
    "\n",
    "            if name not in recognized_faces_dict[face_location]:\n",
    "                recognized_faces_dict[face_location][name] = 0\n",
    "\n",
    "            recognized_faces_dict[face_location][name] += 1\n",
    "\n",
    "    final_recognized_names = []\n",
    "    final_face_locations = []\n",
    "\n",
    "    for face_location, names_dict in recognized_faces_dict.items():\n",
    "        most_common_name = max(names_dict, key=names_dict.get)\n",
    "        final_recognized_names.append(most_common_name)\n",
    "        final_face_locations.append(face_location)\n",
    "\n",
    "    return final_recognized_names, final_face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4858549-8e88-4935-8eed-f374f0bc720f",
   "metadata": {},
   "source": [
    "# updated code for multiple boundaries on face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16b2adb7-f4bb-4df1-9883-a95019d9fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.4):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5, cluster_threshold=30):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations that are close together\n",
    "    if len(face_locations) > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "        \n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                # Find all faces that belong to this cluster\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                \n",
    "                # Aggregate locations and names\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "\n",
    "                # Choose the most common name in the cluster\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                \n",
    "                # Average the locations within the cluster to get a single bounding box\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                \n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return [], []\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bce28-a065-4df9-b8ec-6ec021a0a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c47da69-81fc-453a-bc56-04a1dfdd665b",
   "metadata": {},
   "source": [
    "# modify excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bdf58b-ed7f-4e1f-b2bf-58c5fd796dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.9):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations that are close together\n",
    "    if len(face_locations) > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "        \n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                # Find all faces that belong to this cluster\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                \n",
    "                # Aggregate locations and names\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "\n",
    "                # Choose the most common name in the cluster\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                \n",
    "                # Average the locations within the cluster to get a single bounding box\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                \n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return [], []\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    # Create a new Excel file if it does not exist\n",
    "    if not os.path.exists(output_file):\n",
    "        # Create a DataFrame and save it to a new Excel file\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "        df.to_excel(output_file, index=False)\n",
    "    \n",
    "    # Get the current date\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Load the existing Excel file\n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            sheet_names = xls.sheet_names\n",
    "\n",
    "    # Check if there is already a sheet for today\n",
    "    if today in sheet_names:\n",
    "        df = pd.read_excel(output_file, sheet_name=today)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    \n",
    "    # Identify new members\n",
    "    existing_names = df['Name'].unique()\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(existing_names)]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "    \n",
    "        # Save the updated attendance sheet for today\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "    else:\n",
    "        print(\"No new members detected.\")\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98a0fb-a175-45e9-b8e2-148f9110ce4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9266bc1-8461-4ee6-8faa-58a33526067c",
   "metadata": {},
   "source": [
    "# Summary of Changes:\n",
    "# Caching Encodings: The student encodings are cached in .npy files, avoiding re-encoding on each run.\n",
    "# Removed Unused Code: Removed the unused apply_transformations and verify_face functions.\n",
    "# Optimized Excel Handling: Streamlined how the Excel sheet is handled by reducing redundant checks and operations.\n",
    "# Reduced Image Readings: Passed the image directly to functions, avoiding redundant image loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f4f9d0-634a-4039-9523-bc3457edabb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "known_encodings_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\known_encodings.npy'\n",
    "student_names_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\student_names.npy'\n",
    "\n",
    "# Load and encode student images if not already saved\n",
    "def load_and_encode_images(directory):\n",
    "    if os.path.exists(known_encodings_file) and os.path.exists(student_names_file):\n",
    "        known_encodings = np.load(known_encodings_file, allow_pickle=True)\n",
    "        student_names = np.load(student_names_file, allow_pickle=True)\n",
    "    else:\n",
    "        known_encodings = []\n",
    "        student_names = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                img = face_recognition.load_image_file(image_path)\n",
    "                try:\n",
    "                    img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                    known_encodings.append(img_encoding)\n",
    "                    student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: No face found in {filename}\")\n",
    "        \n",
    "        np.save(known_encodings_file, known_encodings)\n",
    "        np.save(student_names_file, student_names)\n",
    "\n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in a group photo\n",
    "def recognize_faces_in_group_photo(img_rgb, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = face_distances.argmin()\n",
    "        \n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations if needed\n",
    "    if len(face_locations) > 0 and cluster_threshold > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "\n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            if today in xls.sheet_names:\n",
    "                df = pd.read_excel(output_file, sheet_name=today)\n",
    "\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': now})\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(df['Name'].unique())]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n",
    "            mark_attendance(recognized_names)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cc364-ba55-4900-8bcc-b435c8802712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289a558-9282-4c86-b137-4fc5a6ffc194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d81c9ef7-4b3f-4dae-9d79-5b830629d0c0",
   "metadata": {},
   "source": [
    "# ADDED\n",
    "# Changes  \n",
    "# Caching Encodings: The student encodings are cached in .npy files, avoiding re-encoding on each run.\n",
    "# Added Unused Code:  the unused apply_transformations and verify_face functions.\n",
    "# Optimized Excel Handling: Streamlined how the Excel sheet is handled by reducing redundant checks and operations.\n",
    "# Reduced Image Readings: Passed the image directly to functions, avoiding redundant image loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dca2091-6237-4f34-b21b-bb1ab44a3286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "known_encodings_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\known_encodings.npy'\n",
    "student_names_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\student_names.npy'\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Load and encode student images if not already saved\n",
    "def load_and_encode_images(directory):\n",
    "    if os.path.exists(known_encodings_file) and os.path.exists(student_names_file):\n",
    "        known_encodings = np.load(known_encodings_file, allow_pickle=True)\n",
    "        student_names = np.load(student_names_file, allow_pickle=True)\n",
    "    else:\n",
    "        known_encodings = []\n",
    "        student_names = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                img = face_recognition.load_image_file(image_path)\n",
    "                try:\n",
    "                    img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                    known_encodings.append(img_encoding)\n",
    "                    student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "                    \n",
    "                    # Apply transformations and encode them\n",
    "                    transformed_images = apply_transformations(img)\n",
    "                    for transformed_img in transformed_images:\n",
    "                        transformed_encoding = face_recognition.face_encodings(transformed_img)[0]\n",
    "                        known_encodings.append(transformed_encoding)\n",
    "                        student_names.append(os.path.splitext(filename)[0])  # Use the same name for transformed images\n",
    "                    \n",
    "                except IndexError:\n",
    "                    print(f\"Warning: No face found in {filename}\")\n",
    "        \n",
    "        np.save(known_encodings_file, known_encodings)\n",
    "        np.save(student_names_file, student_names)\n",
    "\n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.9):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "# Recognize faces in a group photo\n",
    "def recognize_faces_in_group_photo(img_rgb, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations if needed\n",
    "    if len(face_locations) > 0 and cluster_threshold > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "\n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            if today in xls.sheet_names:\n",
    "                df = pd.read_excel(output_file, sheet_name=today)\n",
    "            else:\n",
    "                df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    \n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': now})\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(df['Name'].unique())]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n",
    "            mark_attendance(recognized_names)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f24e535-e04c-4398-85f1-7c7deb4126a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56cc5bb-3079-42f2-be49-998db4c10c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "known_encodings_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\known_encodings.npy'\n",
    "student_names_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\student_names.npy'\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 10, 1)  # Rotate by 10 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[15:rows-15, 15:cols-15]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Load and encode student images if not already saved\n",
    "def load_and_encode_images(directory):\n",
    "    if os.path.exists(known_encodings_file) and os.path.exists(student_names_file):\n",
    "        known_encodings = np.load(known_encodings_file, allow_pickle=True)\n",
    "        student_names = np.load(student_names_file, allow_pickle=True)\n",
    "    else:\n",
    "        known_encodings = []\n",
    "        student_names = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                img = face_recognition.load_image_file(image_path)\n",
    "                try:\n",
    "                    img_encodings = face_recognition.face_encodings(img)\n",
    "                    if img_encodings:\n",
    "                        for img_encoding in img_encodings:\n",
    "                            known_encodings.append(img_encoding)\n",
    "                            student_names.append(os.path.splitext(filename)[0])\n",
    "                            \n",
    "                            # Apply transformations and encode them\n",
    "                            transformed_images = apply_transformations(img)\n",
    "                            for transformed_img in transformed_images:\n",
    "                                transformed_encodings = face_recognition.face_encodings(transformed_img)\n",
    "                                if transformed_encodings:\n",
    "                                    for transformed_encoding in transformed_encodings:\n",
    "                                        known_encodings.append(transformed_encoding)\n",
    "                                        student_names.append(os.path.splitext(filename)[0])\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: No face found in {filename}\")\n",
    "        \n",
    "        np.save(known_encodings_file, known_encodings)\n",
    "        np.save(student_names_file, student_names)\n",
    "\n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.6):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "# Recognize faces in a group photo\n",
    "def recognize_faces_in_group_photo(img_rgb, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations if needed\n",
    "    if len(face_locations) > 0 and cluster_threshold > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "\n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            if today in xls.sheet_names:\n",
    "                df = pd.read_excel(output_file, sheet_name=today)\n",
    "            else:\n",
    "                df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    \n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': now})\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(df['Name'].unique())]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n",
    "            mark_attendance(recognized_names)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02043b2a-4203-4050-b09b-4b22afe8a731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad8e454-c051-4128-bfb4-cf55cb56c87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "538a43bb-7493-42f6-a001-0602a55840b2",
   "metadata": {},
   "source": [
    "# detect faces using HOG  Tpye 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf2c3fd1-d129-46fa-af57-06a746df68ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# Step 1: Read the image\n",
    "image = cv2.imread(r\"C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img\\acheck2.jpg\")\n",
    "\n",
    "# Step 2: Convert to gray image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Step 3: Get HOG face detector and detect faces\n",
    "hogFaceDetector = dlib.get_frontal_face_detector()\n",
    "faces = hogFaceDetector(gray, 2)\n",
    "\n",
    "# Step 4: Loop through each face and draw a rectangle around it\n",
    "for (i, rect) in enumerate(faces):\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    # Draw a rectangle\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "# Step 5: Display the resulted image\n",
    "cv2.imshow(\"Image\", image)\n",
    "\n",
    "# Step 6: Wait for a key press and close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd8dfb-c1a1-461f-96d5-9aabdc617791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54c024e1-9e78-44a7-a530-5665f7115e71",
   "metadata": {},
   "source": [
    "# hog type 2\n",
    "## # https://www.datasciencelearner.com/opencv/face-detection-recognition-python-hog-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "707c021b-b9b2-41b6-9e66-8aae29eca8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "image =face_recognition.load_image_file(r\"C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img\\acheck2.jpg\")\n",
    "\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "no_of_faces = len(face_locations)\n",
    "print(no_of_faces)\n",
    "\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "for face_location in face_locations:\n",
    "    top,right,bottom,left =face_location\n",
    "    draw_shape = PIL.ImageDraw.Draw(pil_image)\n",
    "    draw_shape.rectangle([left, top, right, bottom],outline=\"red\")\n",
    "\n",
    "#display and save the image\n",
    "pil_image.save(\"saved img/output_image.jpg\")\n",
    "pil_image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
