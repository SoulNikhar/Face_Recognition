{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605e9fe0-389e-4e63-99bf-c56015ab9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(\"OpenCV version:\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffdd8e-58a4-4806-9408-bf44227af2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7130585-da52-4df7-a586-f6f93cdcb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "pixels = cv2.imread('team.jpg')\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(pixels, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "bboxes = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=9, minSize=(30, 30))\n",
    "\n",
    "\n",
    "for (x, y, width, height) in bboxes:\n",
    "    cv2.rectangle(pixels, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow('Detected Objects', pixels)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96264f4f-9928-4e63-80a6-e6ae797405a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('team.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.05,\n",
    "    minNeighbors=3,\n",
    "    minSize=(30, 30),\n",
    "    maxSize=(300, 300)\n",
    ")\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ba81aa8-3400-4039-a9fa-ae922312fdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "347e1f78-595d-42c1-a867-dd2ce1fd9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face detector (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Read the image from the file\n",
    "img = cv2.imread('team.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Optionally, apply histogram equalization for better contrast\n",
    "gray = cv2.equalizeHist(gray)\n",
    "\n",
    "\n",
    "# Detect faces in the image with modified parameters\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "# Draw rectangles around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# Display the output image with the detected faces\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "# Wait indefinitely for a key press\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abd1c50d-f771-450d-b9e8-3c6a8f4310cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('team.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "# Loop until the window is closed by the user\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:  # Optionally allow exiting with ESC key\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037c849-8248-4d57-8378-66055da8a2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7093b74-d29f-4d7d-a45a-aa5b33436ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1c9bff4-47b0-463b-a0a4-3f9acba3f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('team.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    cv2.putText(img, 'Name', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabbd00-a5d8-45c8-a5c6-1cc1c56be0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b32890d-b30e-4bee-b7fc-07edd20c1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# List of names corresponding to each detected face\n",
    "names = ['Person 1', 'Person 2', 'Person 3', 'Person 4','Person 5', 'Person 6', 'Person 7', 'Person 8','Person 1', 'Person 2', 'Person 3', 'Person 4','Person 5', 'Person 6', 'Person 7', 'Person 8']  # Add as many names as there are faces\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('img4.jpeg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "# Ensure that the number of names matches the naumber of detected faces\n",
    "for i, (x, y, w, h) in enumerate(faces):\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    cv2.putText(img, names[i], (x, y - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.2, (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f2a7f-0104-415c-8c9c-aaf2092ce926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f687df34-bcf1-4626-af29-be55e4b1184c",
   "metadata": {},
   "source": [
    "# face recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f47a9d23-abbc-4b70-ab4d-1927b73ee61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.4):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "# Recognize faces in group photo with multiple passes and verification\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5):\n",
    "    img = cv2.imread(image_path)\n",
    "    transformations = apply_transformations(img)\n",
    "    transformations.insert(0, img)  # Include the original image\n",
    "\n",
    "    recognized_faces_dict = {}\n",
    "\n",
    "    for transformed_img in transformations:\n",
    "        transformed_img_rgb = cv2.cvtColor(transformed_img, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(transformed_img_rgb)\n",
    "        face_encodings = face_recognition.face_encodings(transformed_img_rgb, face_locations)\n",
    "\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "\n",
    "            # Track occurrences\n",
    "            if face_location not in recognized_faces_dict:\n",
    "                recognized_faces_dict[face_location] = {}\n",
    "\n",
    "            if name not in recognized_faces_dict[face_location]:\n",
    "                recognized_faces_dict[face_location][name] = 0\n",
    "\n",
    "            recognized_faces_dict[face_location][name] += 1\n",
    "\n",
    "    final_recognized_names = []\n",
    "    final_face_locations = []\n",
    "\n",
    "    for face_location, names_dict in recognized_faces_dict.items():\n",
    "        most_common_name = max(names_dict, key=names_dict.get)\n",
    "        final_recognized_names.append(most_common_name)\n",
    "        final_face_locations.append(face_location)\n",
    "\n",
    "    return final_recognized_names, final_face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4858549-8e88-4935-8eed-f374f0bc720f",
   "metadata": {},
   "source": [
    "# updated code for multiple boundaries on face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16b2adb7-f4bb-4df1-9883-a95019d9fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.4):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5, cluster_threshold=30):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations that are close together\n",
    "    if len(face_locations) > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "        \n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                # Find all faces that belong to this cluster\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                \n",
    "                # Aggregate locations and names\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "\n",
    "                # Choose the most common name in the cluster\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                \n",
    "                # Average the locations within the cluster to get a single bounding box\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                \n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return [], []\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bce28-a065-4df9-b8ec-6ec021a0a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c47da69-81fc-453a-bc56-04a1dfdd665b",
   "metadata": {},
   "source": [
    "# modufy excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41bdf58b-ed7f-4e1f-b2bf-58c5fd796dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new members detected.\n",
      "No new members detected.\n",
      "No new members detected.\n",
      "No new members detected.\n",
      "No new members detected.\n",
      "No new members detected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.4):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5, cluster_threshold=30):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations that are close together\n",
    "    if len(face_locations) > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "        \n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                # Find all faces that belong to this cluster\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                \n",
    "                # Aggregate locations and names\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "\n",
    "                # Choose the most common name in the cluster\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                \n",
    "                # Average the locations within the cluster to get a single bounding box\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                \n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return [], []\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    # Create a new Excel file if it does not exist\n",
    "    if not os.path.exists(output_file):\n",
    "        # Create a DataFrame and save it to a new Excel file\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "        df.to_excel(output_file, index=False)\n",
    "    \n",
    "    # Get the current date\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Load the existing Excel file\n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            sheet_names = xls.sheet_names\n",
    "\n",
    "    # Check if there is already a sheet for today\n",
    "    if today in sheet_names:\n",
    "        df = pd.read_excel(output_file, sheet_name=today)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    \n",
    "    # Identify new members\n",
    "    existing_names = df['Name'].unique()\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(existing_names)]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "    \n",
    "        # Save the updated attendance sheet for today\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "    else:\n",
    "        print(\"No new members detected.\")\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
