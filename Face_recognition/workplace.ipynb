{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "605e9fe0-389e-4e63-99bf-c56015ab9d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(\"OpenCV version:\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ffdd8e-58a4-4806-9408-bf44227af2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7130585-da52-4df7-a586-f6f93cdcb670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "pixels = cv2.imread('team.jpg')\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "gray = cv2.cvtColor(pixels, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "bboxes = classifier.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=9, minSize=(30, 30))\n",
    "\n",
    "\n",
    "for (x, y, width, height) in bboxes:\n",
    "    cv2.rectangle(pixels, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "    \n",
    "cv2.imshow('Detected Objects', pixels)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96264f4f-9928-4e63-80a6-e6ae797405a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('team.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(\n",
    "    gray,\n",
    "    scaleFactor=1.05,\n",
    "    minNeighbors=3,\n",
    "    minSize=(30, 30),\n",
    "    maxSize=(300, 300)\n",
    ")\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ba81aa8-3400-4039-a9fa-ae922312fdc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347e1f78-595d-42c1-a867-dd2ce1fd9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the pre-trained face detector (Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Read the image from the file\n",
    "img = cv2.imread('team.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Optionally, apply histogram equalization for better contrast\n",
    "gray = cv2.equalizeHist(gray)\n",
    "\n",
    "\n",
    "# Detect faces in the image with modified parameters\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "# Draw rectangles around the faces\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# Display the output image with the detected faces\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "# Wait indefinitely for a key press\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Close all OpenCV windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd1c50d-f771-450d-b9e8-3c6a8f4310cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('team.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "# Loop until the window is closed by the user\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:  # Optionally allow exiting with ESC key\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a037c849-8248-4d57-8378-66055da8a2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7093b74-d29f-4d7d-a45a-aa5b33436ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1c9bff4-47b0-463b-a0a4-3f9acba3f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread(r\"C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img\\acheck2.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    cv2.putText(img, 'Name', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabbd00-a5d8-45c8-a5c6-1cc1c56be0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b32890d-b30e-4bee-b7fc-07edd20c1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# List of names corresponding to each detected face\n",
    "names = ['Person 1', 'Person 2', 'Person 3', 'Person 4','Person 5', 'Person 6', 'Person 7', 'Person 8','Person 1', 'Person 2', 'Person 3', 'Person 4','Person 5', 'Person 6', 'Person 7', 'Person 8']  # Add as many names as there are faces\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('img4.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.equalizeHist(gray)\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.05, minNeighbors=3)\n",
    "\n",
    "# Ensure that the number of names matches the naumber of detected faces\n",
    "for i, (x, y, w, h) in enumerate(faces):\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "    cv2.putText(img, names[i], (x, y - 1), cv2.FONT_HERSHEY_SIMPLEX, 0.2, (0, 255, 0), 1)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "\n",
    "while cv2.getWindowProperty('img', cv2.WND_PROP_VISIBLE) >= 1:\n",
    "    if cv2.waitKey(100) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f2a7f-0104-415c-8c9c-aaf2092ce926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5121fbb0-5690-4ca6-8c38-d83ee9c3ce98",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 120\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Run the attendance marking process\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[43mprocess_group_photos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 104\u001b[0m, in \u001b[0;36mprocess_group_photos\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m    103\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(group_images_dir, filename)\n\u001b[1;32m--> 104\u001b[0m     recognized_names, face_locations \u001b[38;5;241m=\u001b[39m \u001b[43mrecognize_faces_in_group_photo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# Mark attendance\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     mark_attendance(recognized_names)\n",
      "Cell \u001b[1;32mIn[13], line 40\u001b[0m, in \u001b[0;36mrecognize_faces_in_group_photo\u001b[1;34m(image_path, known_encodings, student_names)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Detect faces in the group image\u001b[39;00m\n\u001b[0;32m     39\u001b[0m face_locations \u001b[38;5;241m=\u001b[39m face_recognition\u001b[38;5;241m.\u001b[39mface_locations(img_rgb)\n\u001b[1;32m---> 40\u001b[0m face_encodings \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mface_encodings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_rgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m recognized_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m face_encoding \u001b[38;5;129;01min\u001b[39;00m face_encodings:\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36mface_encodings\u001b[1;34m(face_image, known_face_locations, num_jitters, model)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [np\u001b[38;5;241m.\u001b[39marray(face_encoder\u001b[38;5;241m.\u001b[39mcompute_face_descriptor(face_image, raw_landmark_set, num_jitters)) \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\face_recognition\\api.py:214\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03mGiven an image, return the 128-dimension face encoding for each face in the image.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m:return: A list of 128-dimensional face encodings (one for each face in the image)\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m raw_landmarks \u001b[38;5;241m=\u001b[39m _raw_face_landmarks(face_image, known_face_locations, model)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_face_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_landmark_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_jitters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m raw_landmark_set \u001b[38;5;129;01min\u001b[39;00m raw_landmarks]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load image\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            # Handle cases with no faces or multiple faces in the image\n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in group photo\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names):\n",
    "    # Load the group image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    recognized_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # If there are known encodings, find the best match\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "\n",
    "        # Check if a match was found\n",
    "        if best_match_index is not None and matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "    \n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    # Load the existing attendance file or create a new one\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    # Save the updated attendance sheet\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        # Set the bounding box color based on whether the face is recognized\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        \n",
    "        # Add the student's name\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    # Load student images and encode faces\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    # Process each group photo in the directory\n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            # Mark attendance\n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            # Draw bounding boxes around recognized faces\n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            # Display the processed image\n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c979b3-202f-42d9-ae75-96f74b119cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830398e-264a-48c4-826f-079d23057882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94013f41-d982-4d7b-8720-c19ea28a9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load image\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            # Handle cases with no faces or multiple faces in the image\n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in group photo\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.6):\n",
    "    # Load the group image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    recognized_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "    \n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    # Load the existing attendance file or create a new one\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    # Save the updated attendance sheet\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        # Set the bounding box color based on whether the face is recognized\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        \n",
    "        # Add the student's name\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    # Load student images and encode faces\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    # Process each group photo in the directory\n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            # Mark attendance\n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            # Draw bounding boxes around recognized faces\n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            # Display the processed image\n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a1fd4-24f2-4a03-aaef-62f56d380fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdd9da9-36da-4e76-8334-4d0b4406443a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf24709a-97a3-404a-9d67-c50270387da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load image\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            # Handle cases with no faces or multiple faces in the image\n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in group photo\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5):\n",
    "    # Load the group image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    recognized_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "    \n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    # Load the existing attendance file or create a new one\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    # Save the updated attendance sheet\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        # Set the bounding box color based on whether the face is recognized\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        \n",
    "        # Draw a rectangle around the face\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        \n",
    "        # Add the student's name\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    # Load student images and encode faces\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    # Process each group photo in the directory\n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            # Mark attendance\n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            # Draw bounding boxes around recognized faces\n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            # Display the processed image\n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n",
    "\n",
    "# in this code some times it detected someones other face as other one \n",
    "# deleted one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa76c33-e8fa-4841-a899-1ee357896ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13823dc9-0cf6-4f4e-bb31-ae7bf2474ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98bd90b-014c-4a9c-ad17-893bfecbbfac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f687df34-bcf1-4626-af29-be55e4b1184c",
   "metadata": {},
   "source": [
    "# face recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47a9d23-abbc-4b70-ab4d-1927b73ee61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.4):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "# Recognize faces in group photo with multiple passes and verification\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5):\n",
    "    img = cv2.imread(image_path)\n",
    "    transformations = apply_transformations(img)\n",
    "    transformations.insert(0, img)  # Include the original image\n",
    "\n",
    "    recognized_faces_dict = {}\n",
    "\n",
    "    for transformed_img in transformations:\n",
    "        transformed_img_rgb = cv2.cvtColor(transformed_img, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(transformed_img_rgb)\n",
    "        face_encodings = face_recognition.face_encodings(transformed_img_rgb, face_locations)\n",
    "\n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "\n",
    "            # Track occurrences\n",
    "            if face_location not in recognized_faces_dict:\n",
    "                recognized_faces_dict[face_location] = {}\n",
    "\n",
    "            if name not in recognized_faces_dict[face_location]:\n",
    "                recognized_faces_dict[face_location][name] = 0\n",
    "\n",
    "            recognized_faces_dict[face_location][name] += 1\n",
    "\n",
    "    final_recognized_names = []\n",
    "    final_face_locations = []\n",
    "\n",
    "    for face_location, names_dict in recognized_faces_dict.items():\n",
    "        most_common_name = max(names_dict, key=names_dict.get)\n",
    "        final_recognized_names.append(most_common_name)\n",
    "        final_face_locations.append(face_location)\n",
    "\n",
    "    return final_recognized_names, final_face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n",
    "\n",
    "# deleted "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4858549-8e88-4935-8eed-f374f0bc720f",
   "metadata": {},
   "source": [
    "# updated code for multiple boundaries on face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16b2adb7-f4bb-4df1-9883-a95019d9fd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.4):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.5, cluster_threshold=30):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations that are close together\n",
    "    if len(face_locations) > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "        \n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                # Find all faces that belong to this cluster\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                \n",
    "                # Aggregate locations and names\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "\n",
    "                # Choose the most common name in the cluster\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                \n",
    "                # Average the locations within the cluster to get a single bounding box\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                \n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return [], []\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    df = pd.concat([df, new_entries[~new_entries['Name'].isin(df['Name'])]], ignore_index=True)\n",
    "\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n",
    "\n",
    "# medium effective "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109bce28-a065-4df9-b8ec-6ec021a0a1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c47da69-81fc-453a-bc56-04a1dfdd665b",
   "metadata": {},
   "source": [
    "# modify excel file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41bdf58b-ed7f-4e1f-b2bf-58c5fd796dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new members detected.\n",
      "No new members detected.\n",
      "No new members detected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.9):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "def recognize_faces_in_group_photo(image_path, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces in the group image\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        # Find the best match index with a stricter check\n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "            if matches[best_match_index] and face_distances[best_match_index] <= tolerance:\n",
    "                name = student_names[best_match_index]\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations that are close together\n",
    "    if len(face_locations) > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "        \n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                # Find all faces that belong to this cluster\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                \n",
    "                # Aggregate locations and names\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "\n",
    "                # Choose the most common name in the cluster\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                \n",
    "                # Average the locations within the cluster to get a single bounding box\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                \n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return [], []\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    # Create a new Excel file if it does not exist\n",
    "    if not os.path.exists(output_file):\n",
    "        # Create a DataFrame and save it to a new Excel file\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "        df.to_excel(output_file, index=False)\n",
    "    \n",
    "    # Get the current date\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Load the existing Excel file\n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            sheet_names = xls.sheet_names\n",
    "\n",
    "    # Check if there is already a sheet for today\n",
    "    if today in sheet_names:\n",
    "        df = pd.read_excel(output_file, sheet_name=today)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    # Get the current timestamp\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Add recognized names to the attendance list\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': dt_string})\n",
    "    \n",
    "    # Identify new members\n",
    "    existing_names = df['Name'].unique()\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(existing_names)]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "    \n",
    "        # Save the updated attendance sheet for today\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "    else:\n",
    "        print(\"No new members detected.\")\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6  # Adjust font size for visibility\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(image_path, known_encodings, student_names)\n",
    "            \n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            img = cv2.imread(image_path)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98a0fb-a175-45e9-b8e2-148f9110ce4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9266bc1-8461-4ee6-8faa-58a33526067c",
   "metadata": {},
   "source": [
    "# Summary of Changes:\n",
    "# Caching Encodings: The student encodings are cached in .npy files, avoiding re-encoding on each run.\n",
    "# Removed Unused Code: Removed the unused apply_transformations and verify_face functions.\n",
    "# Optimized Excel Handling: Streamlined how the Excel sheet is handled by reducing redundant checks and operations.\n",
    "# Reduced Image Readings: Passed the image directly to functions, avoiding redundant image loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f4f9d0-634a-4039-9523-bc3457edabb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\NIKHAR BEHERA\\\\Anaconda\\\\Face_advr\\\\attend.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 131\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Run the attendance marking process\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[43mprocess_group_photos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 122\u001b[0m, in \u001b[0;36mprocess_group_photos\u001b[1;34m()\u001b[0m\n\u001b[0;32m    119\u001b[0m img_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m    121\u001b[0m recognized_names, face_locations \u001b[38;5;241m=\u001b[39m recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n\u001b[1;32m--> 122\u001b[0m \u001b[43mmark_attendance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecognized_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m draw_bounding_boxes(img, face_locations, recognized_names)\n\u001b[0;32m    125\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttendance\u001b[39m\u001b[38;5;124m'\u001b[39m, img)\n",
      "Cell \u001b[1;32mIn[2], line 100\u001b[0m, in \u001b[0;36mmark_attendance\u001b[1;34m(names, output_file)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_entries\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     99\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, new_entries], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreplace\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m    101\u001b[0m         df\u001b[38;5;241m.\u001b[39mto_excel(writer, sheet_name\u001b[38;5;241m=\u001b[39mtoday, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:60\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     58\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1219\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1216\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1217\u001b[0m )\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\common.py:868\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    869\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    871\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\NIKHAR BEHERA\\\\Anaconda\\\\Face_advr\\\\attend.xlsx'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "known_encodings_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\known_encodings.npy'\n",
    "student_names_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\student_names.npy'\n",
    "\n",
    "# Load and encode student images if not already saved\n",
    "def load_and_encode_images(directory):\n",
    "    if os.path.exists(known_encodings_file) and os.path.exists(student_names_file):\n",
    "        known_encodings = np.load(known_encodings_file, allow_pickle=True)\n",
    "        student_names = np.load(student_names_file, allow_pickle=True)\n",
    "    else:\n",
    "        known_encodings = []\n",
    "        student_names = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                img = face_recognition.load_image_file(image_path)\n",
    "                try:\n",
    "                    img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                    known_encodings.append(img_encoding)\n",
    "                    student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: No face found in {filename}\")\n",
    "        \n",
    "        np.save(known_encodings_file, known_encodings)\n",
    "        np.save(student_names_file, student_names)\n",
    "\n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in a group photo\n",
    "def recognize_faces_in_group_photo(img_rgb, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = face_distances.argmin()\n",
    "        \n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "        \n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations if needed\n",
    "    if len(face_locations) > 0 and cluster_threshold > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "\n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attend.xlsx'):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            if today in xls.sheet_names:\n",
    "                df = pd.read_excel(output_file, sheet_name=today)\n",
    "\n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': now})\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(df['Name'].unique())]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n",
    "            mark_attendance(recognized_names)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cc364-ba55-4900-8bcc-b435c8802712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289a558-9282-4c86-b137-4fc5a6ffc194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d81c9ef7-4b3f-4dae-9d79-5b830629d0c0",
   "metadata": {},
   "source": [
    "# ADDED\n",
    "# Changes  \n",
    "# Caching Encodings: The student encodings are cached in .npy files, avoiding re-encoding on each run.\n",
    "# Added Unused Code:  the unused apply_transformations and verify_face functions.\n",
    "# Optimized Excel Handling: Streamlined how the Excel sheet is handled by reducing redundant checks and operations.\n",
    "# Reduced Image Readings: Passed the image directly to functions, avoiding redundant image loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f56b8e3-7dfa-441c-aa35-8ce631373f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider code 1\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "known_encodings_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\known_encodings.npy'\n",
    "student_names_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\student_names.npy'\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.1, fy=1.1, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 5, 1)  # Rotate by 5 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[10:rows-10, 10:cols-10]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Load and encode student images if not already saved\n",
    "def load_and_encode_images(directory):\n",
    "    if os.path.exists(known_encodings_file) and os.path.exists(student_names_file):\n",
    "        known_encodings = np.load(known_encodings_file, allow_pickle=True)\n",
    "        student_names = np.load(student_names_file, allow_pickle=True)\n",
    "    else:\n",
    "        known_encodings = []\n",
    "        student_names = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                img = face_recognition.load_image_file(image_path)\n",
    "                try:\n",
    "                    img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                    known_encodings.append(img_encoding)\n",
    "                    student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "                    \n",
    "                    # Apply transformations and encode them\n",
    "                    transformed_images = apply_transformations(img)\n",
    "                    for transformed_img in transformed_images:\n",
    "                        transformed_encoding = face_recognition.face_encodings(transformed_img)[0]\n",
    "                        known_encodings.append(transformed_encoding)\n",
    "                        student_names.append(os.path.splitext(filename)[0])  # Use the same name for transformed images\n",
    "                    \n",
    "                except IndexError:\n",
    "                    print(f\"Warning: No face found in {filename}\")\n",
    "        \n",
    "        np.save(known_encodings_file, known_encodings)\n",
    "        np.save(student_names_file, student_names)\n",
    "\n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.9):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "# Recognize faces in a group photo\n",
    "def recognize_faces_in_group_photo(img_rgb, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations if needed\n",
    "    if len(face_locations) > 0 and cluster_threshold > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "\n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            if today in xls.sheet_names:\n",
    "                df = pd.read_excel(output_file, sheet_name=today)\n",
    "            else:\n",
    "                df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    \n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': now})\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(df['Name'].unique())]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n",
    "            mark_attendance(recognized_names)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f24e535-e04c-4398-85f1-7c7deb4126a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d56cc5bb-3079-42f2-be49-998db4c10c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider code 2\n",
    "\n",
    "import cv2\n",
    "import face_recognition\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Directories for student images and group photos\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "known_encodings_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\known_encodings.npy'\n",
    "student_names_file = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\student_names.npy'\n",
    "\n",
    "# Apply slight transformations to the image\n",
    "def apply_transformations(img):\n",
    "    transformations = []\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Zoom in\n",
    "    zoom_img = cv2.resize(img, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_LINEAR)\n",
    "    zoom_img = zoom_img[(zoom_img.shape[0] - rows) // 2:(zoom_img.shape[0] + rows) // 2,\n",
    "                        (zoom_img.shape[1] - cols) // 2:(zoom_img.shape[1] + cols) // 2]\n",
    "    transformations.append(zoom_img)\n",
    "\n",
    "    # Rotate slightly\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 10, 1)  # Rotate by 10 degrees\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    transformations.append(rotated_img)\n",
    "\n",
    "    # Crop slightly\n",
    "    crop_img = img[15:rows-15, 15:cols-15]\n",
    "    crop_img = cv2.resize(crop_img, (cols, rows))\n",
    "    transformations.append(crop_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Load and encode student images if not already saved\n",
    "def load_and_encode_images(directory):\n",
    "    if os.path.exists(known_encodings_file) and os.path.exists(student_names_file):\n",
    "        known_encodings = np.load(known_encodings_file, allow_pickle=True)\n",
    "        student_names = np.load(student_names_file, allow_pickle=True)\n",
    "    else:\n",
    "        known_encodings = []\n",
    "        student_names = []\n",
    "        \n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                image_path = os.path.join(directory, filename)\n",
    "                img = face_recognition.load_image_file(image_path)\n",
    "                try:\n",
    "                    img_encodings = face_recognition.face_encodings(img)\n",
    "                    if img_encodings:\n",
    "                        for img_encoding in img_encodings:\n",
    "                            known_encodings.append(img_encoding)\n",
    "                            student_names.append(os.path.splitext(filename)[0])\n",
    "                            \n",
    "                            # Apply transformations and encode them\n",
    "                            transformed_images = apply_transformations(img)\n",
    "                            for transformed_img in transformed_images:\n",
    "                                transformed_encodings = face_recognition.face_encodings(transformed_img)\n",
    "                                if transformed_encodings:\n",
    "                                    for transformed_encoding in transformed_encodings:\n",
    "                                        known_encodings.append(transformed_encoding)\n",
    "                                        student_names.append(os.path.splitext(filename)[0])\n",
    "                except IndexError:\n",
    "                    print(f\"Warning: No face found in {filename}\")\n",
    "        \n",
    "        np.save(known_encodings_file, known_encodings)\n",
    "        np.save(student_names_file, student_names)\n",
    "\n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Verify a recognized face by comparing with multiple images of the person\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.6):\n",
    "    verification_threshold = 2  # Number of matches required to confirm recognition\n",
    "    verified = False\n",
    "    name = \"Unknown\"\n",
    "\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "    \n",
    "    if len(face_distances) > 0:\n",
    "        best_match_index = face_distances.argmin()\n",
    "        if matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            \n",
    "            # Verify with multiple images\n",
    "            match_count = sum(matches)\n",
    "            if match_count >= verification_threshold:\n",
    "                verified = True\n",
    "    \n",
    "    return verified, name\n",
    "\n",
    "# Recognize faces in a group photo\n",
    "def recognize_faces_in_group_photo(img_rgb, known_encodings, student_names, tolerance=0.6, cluster_threshold=30):\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "        recognized_names.append(name)\n",
    "\n",
    "    # Cluster face locations if needed\n",
    "    if len(face_locations) > 0 and cluster_threshold > 0:\n",
    "        face_locations_array = np.array(face_locations)\n",
    "        distances = cdist(face_locations_array, face_locations_array)\n",
    "        clusters = np.argwhere(distances < cluster_threshold)\n",
    "\n",
    "        unique_clusters = set()\n",
    "        final_recognized_names = []\n",
    "        final_face_locations = []\n",
    "\n",
    "        for i, loc in enumerate(face_locations_array):\n",
    "            cluster_id = i\n",
    "            if cluster_id not in unique_clusters:\n",
    "                cluster_indices = np.unique(clusters[np.any(clusters == i, axis=1)][:, 1])\n",
    "                clustered_locations = [face_locations_array[idx] for idx in cluster_indices]\n",
    "                clustered_names = [recognized_names[idx] for idx in cluster_indices]\n",
    "                most_common_name = max(set(clustered_names), key=clustered_names.count)\n",
    "                avg_location = np.mean(clustered_locations, axis=0).astype(int)\n",
    "                final_recognized_names.append(most_common_name)\n",
    "                final_face_locations.append(tuple(avg_location))\n",
    "                unique_clusters.add(cluster_id)\n",
    "\n",
    "        return final_recognized_names, final_face_locations\n",
    "\n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\attendance.xlsx'):\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    \n",
    "    if os.path.exists(output_file):\n",
    "        with pd.ExcelFile(output_file) as xls:\n",
    "            if today in xls.sheet_names:\n",
    "                df = pd.read_excel(output_file, sheet_name=today)\n",
    "            else:\n",
    "                df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "    \n",
    "    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    new_entries = pd.DataFrame({'Name': names, 'Time': now})\n",
    "    new_entries = new_entries[~new_entries['Name'].isin(df['Name'].unique())]\n",
    "    \n",
    "    if not new_entries.empty:\n",
    "        df = pd.concat([df, new_entries], ignore_index=True)\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name=today, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        color = (0, 255, 0) if name != \"Unknown\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), color, 2)\n",
    "        font_scale = 0.4 if name != \"Unknown\" else 0.6\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n",
    "            mark_attendance(recognized_names)\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Run the attendance marking process\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02043b2a-4203-4050-b09b-4b22afe8a731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54c024e1-9e78-44a7-a530-5665f7115e71",
   "metadata": {},
   "source": [
    "# HOG \n",
    "## # https://www.datasciencelearner.com/opencv/face-detection-recognition-python-hog-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707c021b-b9b2-41b6-9e66-8aae29eca8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import face_recognition\n",
    "\n",
    "image =face_recognition.load_image_file(r\"C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img\\acheck2.jpg\")\n",
    "\n",
    "face_locations = face_recognition.face_locations(image)\n",
    "no_of_faces = len(face_locations)\n",
    "print(no_of_faces)\n",
    "\n",
    "pil_image = PIL.Image.fromarray(image)\n",
    "for face_location in face_locations:\n",
    "    top,right,bottom,left =face_location\n",
    "    draw_shape = PIL.ImageDraw.Draw(pil_image)\n",
    "    draw_shape.rectangle([left, top, right, bottom],outline=\"red\")\n",
    "\n",
    "#display and save the image\n",
    "# pil_image.save(\"saved img/output_image.jpg\")\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09e12cf-920b-4d74-a6ff-dbe62ba8e4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "538a43bb-7493-42f6-a001-0602a55840b2",
   "metadata": {},
   "source": [
    "# detect faces using HOG  + Haar Cascade + CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54dd8dfb-c1a1-461f-96d5-9aabdc617791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "\n",
    "# Step 1: Read the image\n",
    "image = cv2.imread(r\"C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img\\acheck2.jpg\")\n",
    "\n",
    "# Step 2: Convert the image to grayscale\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Step 3: Load Haar cascade \n",
    "haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "haar_faces = haar_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "for (x, y, w, h) in haar_faces:\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (255, 0, 0), 2)  # Draw blue rectangle\n",
    "\n",
    "# Step 4: Use HOG face detector \n",
    "hogFaceDetector = dlib.get_frontal_face_detector()\n",
    "faces = hogFaceDetector(gray, 2)\n",
    "for rect in faces:\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Draw green rectangle\n",
    "\n",
    "# Step 5: Use CNN face detector \n",
    "cnn_face_detector = dlib.cnn_face_detection_model_v1(\"mmod_human_face_detector.dat\")\n",
    "cnn_faces = cnn_face_detector(gray, 1)\n",
    "for face in cnn_faces:\n",
    "    x = face.rect.left()\n",
    "    y = face.rect.top()\n",
    "    w = face.rect.right() - x\n",
    "    h = face.rect.bottom() - y\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Draw red rectangle\n",
    "\n",
    "# Step 6: Display the resulting image\n",
    "cv2.imshow(\"Image\", image)\n",
    "\n",
    "# Step 7: Wait for a key press and close the window\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e8f38-8b5e-4e4f-a578-300587ce12de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23eadc4-30a1-47fb-b569-649f21f589a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c71ceb-cab0-4b4b-a410-12c489db6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 9 faces using HOG model\n",
      "Detected 3 faces using CNN model\n",
      "HOG model detected more faces accurately in acheck2.jpg.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_adv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[43mprocess_group_photos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 109\u001b[0m, in \u001b[0;36mprocess_group_photos\u001b[1;34m()\u001b[0m\n\u001b[0;32m    106\u001b[0m     face_locations \u001b[38;5;241m=\u001b[39m face_locations_cnn\n\u001b[0;32m    108\u001b[0m \u001b[38;5;66;03m# Mark attendance\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m \u001b[43mmark_attendance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecognized_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;66;03m# Draw bounding boxes\u001b[39;00m\n\u001b[0;32m    112\u001b[0m draw_bounding_boxes(img, face_locations, recognized_names)\n",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m, in \u001b[0;36mmark_attendance\u001b[1;34m(names, output_file)\u001b[0m\n\u001b[0;32m     65\u001b[0m new_entries \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m: [name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues],\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m: [dt_string] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m([name \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues])\n\u001b[0;32m     68\u001b[0m })\n\u001b[0;32m     70\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, new_entries], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 71\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\core\\generic.py:2252\u001b[0m, in \u001b[0;36mNDFrame.to_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options)\u001b[0m\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mformats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexcel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExcelFormatter\n\u001b[0;32m   2241\u001b[0m formatter \u001b[38;5;241m=\u001b[39m ExcelFormatter(\n\u001b[0;32m   2242\u001b[0m     df,\n\u001b[0;32m   2243\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2250\u001b[0m     inf_rep\u001b[38;5;241m=\u001b[39minf_rep,\n\u001b[0;32m   2251\u001b[0m )\n\u001b[1;32m-> 2252\u001b[0m \u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexcel_writer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2254\u001b[0m \u001b[43m    \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msheet_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstartcol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstartcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreeze_panes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreeze_panes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\formats\\excel.py:934\u001b[0m, in \u001b[0;36mExcelFormatter.write\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001b[0m\n\u001b[0;32m    930\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    932\u001b[0m     \u001b[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001b[39;00m\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m     writer \u001b[38;5;241m=\u001b[39m \u001b[43mExcelWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[abstract]\u001b[39;49;00m\n\u001b[0;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[0;32m    936\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m     need_save \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:60\u001b[0m, in \u001b[0;36mOpenpyxlWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenpyxl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mworkbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Workbook\n\u001b[0;32m     58\u001b[0m engine_kwargs \u001b[38;5;241m=\u001b[39m combine_kwargs(engine_kwargs, kwargs)\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mif_sheet_exists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_sheet_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# ExcelWriter replaced \"a\" by \"r+\" to allow us to first read the excel file from\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# the file and later write to it\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode:  \u001b[38;5;66;03m# Load from existing workbook\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1219\u001b[0m, in \u001b[0;36mExcelWriter.__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m   1216\u001b[0m     cast(IO[\u001b[38;5;28mbytes\u001b[39m], path), compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m   1217\u001b[0m )\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, ExcelWriter):\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_sheet \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m date_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\common.py:737\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 737\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda\\envs\\dummy\\lib\\site-packages\\pandas\\io\\common.py:600\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    598\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_adv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import face_recognition\n",
    "\n",
    "# Paths to the directories\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "group_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "\n",
    "# Load and encode student images\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            \n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                known_encodings.append(img_encoding)\n",
    "                student_names.append(os.path.splitext(filename)[0])  # Use the filename without extension as the name\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "    \n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Recognize faces in group photo using HOG or CNN model\n",
    "def recognize_faces_in_group_photo(image, known_encodings, student_names, model='hog'):\n",
    "    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    face_locations = face_recognition.face_locations(img_rgb, model=model)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "    \n",
    "    print(f\"Detected {len(face_locations)} faces using {model.upper()} model\")\n",
    "\n",
    "    recognized_names = []\n",
    "    \n",
    "    for face_encoding in face_encodings:\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)\n",
    "        face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "        best_match_index = None\n",
    "        \n",
    "        if len(face_distances) > 0:\n",
    "            best_match_index = face_distances.argmin()\n",
    "        \n",
    "        if best_match_index is not None and matches[best_match_index]:\n",
    "            name = student_names[best_match_index]\n",
    "            recognized_names.append(name)\n",
    "    \n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Mark attendance in an Excel file\n",
    "def mark_attendance(names, output_file=r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_adv\\Attendance.xlsx'):\n",
    "    try:\n",
    "        df = pd.read_excel(output_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=['Name', 'Time'])\n",
    "\n",
    "    now = datetime.now()\n",
    "    dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    new_entries = pd.DataFrame({\n",
    "        'Name': [name for name in names if name not in df['Name'].values],\n",
    "        'Time': [dt_string] * len([name for name in names if name not in df['Name'].values])\n",
    "    })\n",
    "\n",
    "    df = pd.concat([df, new_entries], ignore_index=True)\n",
    "    df.to_excel(output_file, index=False)\n",
    "\n",
    "# Draw bounding boxes on recognized faces\n",
    "def draw_bounding_boxes(img, face_locations, recognized_names):\n",
    "    for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "        cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(img, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# Process group photos and mark attendance\n",
    "def process_group_photos():\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "    \n",
    "    for filename in os.listdir(group_images_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            image_path = os.path.join(group_images_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Error loading image {filename}\")\n",
    "                continue\n",
    "            \n",
    "            # Recognize faces using HOG model\n",
    "            recognized_names_hog, face_locations_hog = recognize_faces_in_group_photo(img, known_encodings, student_names, model='hog')\n",
    "            \n",
    "            # Recognize faces using CNN model\n",
    "            recognized_names_cnn, face_locations_cnn = recognize_faces_in_group_photo(img, known_encodings, student_names, model='cnn')\n",
    "            \n",
    "            # Compare results and select the best model\n",
    "            if len(recognized_names_hog) > len(recognized_names_cnn):\n",
    "                print(f\"HOG model detected more faces accurately in {filename}.\")\n",
    "                recognized_names = recognized_names_hog\n",
    "                face_locations = face_locations_hog\n",
    "            else:\n",
    "                print(f\"CNN model detected more faces accurately in {filename}.\")\n",
    "                recognized_names = recognized_names_cnn\n",
    "                face_locations = face_locations_cnn\n",
    "            \n",
    "            # Mark attendance\n",
    "            mark_attendance(recognized_names)\n",
    "            \n",
    "            # Draw bounding boxes\n",
    "            draw_bounding_boxes(img, face_locations, recognized_names)\n",
    "            \n",
    "            cv2.imshow('Attendance', img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_group_photos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786cb206-7486-453a-a784-a00c01e3099f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07f6cd85-0f55-435f-8c00-dd9a0fadaacd",
   "metadata": {},
   "source": [
    "# date : 21 - oct - 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d1c26e2-40ae-4037-b88c-1e3879294994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better but still need improve \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "# Function to normalize images (resize, convert, etc.)\n",
    "def normalize_image(image, target_size=(150, 150)):\n",
    "    image_resized = cv2.resize(image, target_size)\n",
    "    return image_resized\n",
    "\n",
    "# Function to apply augmentations (rotations, zooms, brightness) to a single image\n",
    "def generate_augmented_images(img):\n",
    "    transformations = []\n",
    "\n",
    "    # Apply various rotations\n",
    "    for angle in [-10, -5, 0, 5, 10]:\n",
    "        M = cv2.getRotationMatrix2D((img.shape[1] // 2, img.shape[0] // 2), angle, 1)\n",
    "        rotated_img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n",
    "        transformations.append(rotated_img)\n",
    "\n",
    "    # Apply various zooms\n",
    "    for scale in [1.05, 1.1, 1.2]:\n",
    "        zoomed_img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)\n",
    "        zoomed_img = zoomed_img[(zoomed_img.shape[0] - img.shape[0]) // 2: (zoomed_img.shape[0] + img.shape[0]) // 2,\n",
    "                                (zoomed_img.shape[1] - img.shape[1]) // 2: (zoomed_img.shape[1] + img.shape[1]) // 2]\n",
    "        transformations.append(zoomed_img)\n",
    "\n",
    "    # Adjust brightness\n",
    "    for alpha in [0.8, 1.2]:\n",
    "        adjusted_img = cv2.convertScaleAbs(img, alpha=alpha)\n",
    "        transformations.append(adjusted_img)\n",
    "\n",
    "    return transformations\n",
    "\n",
    "# Function to load and encode individual images from directory\n",
    "def load_and_encode_images(directory):\n",
    "    known_encodings = []\n",
    "    student_names = []\n",
    "    student_image_dict = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Extract student name from file name (before the first '_')\n",
    "            name = filename.split('_')[0].split('.')[0]  # Remove the extension\n",
    "            image_path = os.path.join(directory, filename)\n",
    "            img = face_recognition.load_image_file(image_path)\n",
    "            img = normalize_image(img)\n",
    "\n",
    "            # Keep track of all encodings for a student\n",
    "            if name not in student_image_dict:\n",
    "                student_image_dict[name] = []\n",
    "\n",
    "            try:\n",
    "                img_encoding = face_recognition.face_encodings(img)[0]\n",
    "                student_image_dict[name].append(img_encoding)\n",
    "\n",
    "                # Generate augmented images and store their encodings\n",
    "                augmented_images = generate_augmented_images(img)\n",
    "                for augmented_img in augmented_images:\n",
    "                    augmented_img_rgb = cv2.cvtColor(augmented_img, cv2.COLOR_BGR2RGB)\n",
    "                    augmented_encodings = face_recognition.face_encodings(augmented_img_rgb)\n",
    "                    if augmented_encodings:\n",
    "                        student_image_dict[name].append(augmented_encodings[0])\n",
    "\n",
    "            except IndexError:\n",
    "                print(f\"Warning: No face found in {filename}\")\n",
    "\n",
    "    # Combine encodings from all images of a student\n",
    "    for name, encodings in student_image_dict.items():\n",
    "        known_encodings.extend(encodings)\n",
    "        student_names.extend([name] * len(encodings))\n",
    "\n",
    "    return known_encodings, student_names\n",
    "\n",
    "# Function to verify if a face encoding matches any known encoding\n",
    "def verify_face(known_encodings, face_encoding, student_names, tolerance=0.50):\n",
    "    matches = face_recognition.compare_faces(known_encodings, face_encoding, tolerance=tolerance)\n",
    "    face_distances = face_recognition.face_distance(known_encodings, face_encoding)\n",
    "\n",
    "    if any(matches):\n",
    "        best_match_index = np.argmin(face_distances)\n",
    "        return True, student_names[best_match_index]\n",
    "    else:\n",
    "        return False, \"Unknown\"\n",
    "\n",
    "# Function to recognize faces in a group photo\n",
    "def recognize_faces_in_group_photo(img_rgb, known_encodings, student_names, tolerance=0.50):\n",
    "    face_locations = face_recognition.face_locations(img_rgb)\n",
    "    face_encodings = face_recognition.face_encodings(img_rgb, face_locations)\n",
    "\n",
    "    recognized_names = []\n",
    "    for face_encoding in face_encodings:\n",
    "        verified, name = verify_face(known_encodings, face_encoding, student_names, tolerance)\n",
    "        recognized_names.append(name)\n",
    "\n",
    "    return recognized_names, face_locations\n",
    "\n",
    "# Function to process all group photos and recognize faces\n",
    "def process_group_photos(group_photos_dir, individual_images_dir):\n",
    "    # Load and encode individual images\n",
    "    known_encodings, student_names = load_and_encode_images(individual_images_dir)\n",
    "\n",
    "    # Process each group photo in the group photo directory\n",
    "    for filename in os.listdir(group_photos_dir):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "            group_photo_path = os.path.join(group_photos_dir, filename)\n",
    "            \n",
    "            # Load group photo\n",
    "            group_photo = cv2.imread(group_photo_path)\n",
    "            img_rgb = cv2.cvtColor(group_photo, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Recognize faces in the group photo\n",
    "            recognized_names, face_locations = recognize_faces_in_group_photo(img_rgb, known_encodings, student_names)\n",
    "\n",
    "            # Draw rectangles around faces and annotate names\n",
    "            for (top, right, bottom, left), name in zip(face_locations, recognized_names):\n",
    "                # Set rectangle color based on recognition status\n",
    "                box_color = (0, 0, 255) if name == \"Unknown\" else (0, 255, 0)\n",
    "                cv2.rectangle(group_photo, (left, top), (right, bottom), box_color, 2)\n",
    "\n",
    "                # Set text color based on recognition status\n",
    "                text_color = (0, 0, 255) if name == \"Unknown\" else (0, 255, 0)\n",
    "                cv2.putText(group_photo, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 2)\n",
    "\n",
    "            # Show the output image with recognized faces\n",
    "            cv2.imshow(\"Group Photo\", group_photo)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "group_photos_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\grp_img'\n",
    "individual_images_dir = r'C:\\Users\\NIKHAR BEHERA\\Anaconda\\Face_advr\\indi_img'\n",
    "process_group_photos(group_photos_dir, individual_images_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc9ea5-8c07-4448-bd87-2317921741bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f81453-770d-45e0-b951-a8145cacf3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
